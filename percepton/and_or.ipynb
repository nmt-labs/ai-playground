{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percepton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Perceptron` class to exececute predictions and trainings <br>\n",
    "- Class variables\n",
    "  - `weight` : list of `n` random numbers (weights) between -1 and 1\n",
    "  - `bias` : a random number between -1 and 1\n",
    "- Class methods\n",
    "  - `predict` :\n",
    "    - arguments : \n",
    "      - `inputs` : list  \n",
    "    - return : 1 if the weighted sum is greater than or equal to 0, and 0 otherwise\n",
    "    given an `input` it predicts the `output`.\n",
    "  - `train` : \n",
    "    - arguments :\n",
    "      - `training_data` : list of tuples. Each tuple contains an input vector and its corresponding target output.\n",
    "      - `epochs` :  number of times the training data is used to update the weights of the neural network.\n",
    "      - `learning_rate` : hyperparameter that controls the step size of the weight updates.\n",
    "    - return : -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, n):\n",
    "        self.weights = [random.uniform(-1, 1) for _ in range(n)]\n",
    "        self.bias = random.uniform(-1, 1)\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        weighted_sum = sum(w * x for w, x in zip(self.weights, inputs)) + self.bias\n",
    "        return 1 if weighted_sum >= 0 else 0\n",
    "\n",
    "    def train(self, training_data, epochs, learning_rate):\n",
    "        for _ in range(epochs):\n",
    "            for inputs, target in training_data:\n",
    "                prediction = self.predict(inputs)\n",
    "                error = target - prediction\n",
    "                for i in range(len(self.weights)):\n",
    "                    self.weights[i] += learning_rate * error * inputs[i]\n",
    "                self.bias += learning_rate * error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a training data `training_data` to run `Perceptron.train` based on the choosen arguments.\n",
    "- arguments :\n",
    "  - `gate` : a string `\"AND\"` or `\"OR\"`\n",
    "  - `n` : number of inputs\n",
    "- return : new `Perceptron` with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(gate, n):\n",
    "    if gate == \"AND\":\n",
    "        training_data = [(inputs, int(all(inputs))) for inputs in (zip(*[[0, 1] for _ in range(n)]))]\n",
    "    elif gate == \"OR\":\n",
    "        training_data = [(inputs, int(any(inputs))) for inputs in (zip(*[[0, 1] for _ in range(n)]))]\n",
    "\n",
    "    perceptron = Perceptron(n)\n",
    "    perceptron.train(training_data, epochs=1000, learning_rate=0.1)\n",
    "\n",
    "    return perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates a list of test data `test_data` then computes the predicted output of the perceptron for each `test_data` input. After, it prints the results.\n",
    "- arguments :\n",
    "  - `perceptron` : an `Perceptron` object\n",
    "  - `n` : number of inputs\n",
    "- return : -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(perceptron, n):\n",
    "    test_data = [(inputs, int(all(inputs))) for inputs in (zip(*[[0, 1] for _ in range(n)]))]\n",
    "    for inputs, target in test_data:\n",
    "        prediction = perceptron.predict(inputs)\n",
    "        print(f\"Input: {inputs} => Output: {prediction} (Expected: {target})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron to OR with 4 inputs: \n",
      "Input: (0, 0, 0, 0) => Output: 0 (Expected: 0)\n",
      "Input: (1, 1, 1, 1) => Output: 1 (Expected: 1)\n"
     ]
    }
   ],
   "source": [
    "n = int(input(\"Insert number of inputs\"))\n",
    "gate = input(\"Type \\\"AND\\\" or \\\"OR\\\"\")\n",
    "perceptron = train(gate, n)\n",
    "print(f\"Perceptron to {gate} with {n} inputs: \")\n",
    "test(perceptron, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xor test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a list of outputs for the XOR operation `xor_test_data` iterating the list of tuples with the `^` operator, then the perceptron is trained for the `\"AND\"` gate. <br>\n",
    "However, the perceptron trained to perform the logical AND operation is not capable of performing the logical XOR operation because the XOR operation is not linearly separable. Therefore, the perceptron will not be able to learn the correct weights to perform the XOR operation. To perform the XOR operation, a more complex neural network architecture is required, such as a multi-layer perceptron or a feedforward neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron to XOR:\n",
      "Input: (0, 0) => Output: 0 (Expected: 0)\n",
      "Input: (0, 1) => Output: 1 (Expected: 1)\n",
      "Input: (1, 0) => Output: 1 (Expected: 1)\n",
      "Input: (1, 1) => Output: 1 (Expected: 0)\n"
     ]
    }
   ],
   "source": [
    "xor_test_data = [(inputs, int(inputs[0] ^ inputs[1])) for inputs in [(0, 0), (0, 1), (1, 0), (1, 1)]]\n",
    "and_perceptron = train(\"AND\", 4)\n",
    "print(\"Perceptron to XOR:\")\n",
    "for inputs, target in xor_test_data:\n",
    "    prediction = and_perceptron.predict(inputs)\n",
    "    print(f\"Input: {inputs} => Output: {prediction} (Expected: {target})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
